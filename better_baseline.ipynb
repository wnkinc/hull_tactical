{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebec976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (9021, 95) | y shape: (9021,)\n",
      "Baseline feature columns: 95\n",
      "Baseline (last return) Allocation Sharpe-like per fold:\n",
      "  Fold 1: -0.034048\n",
      "  Fold 2: -0.022892\n",
      "  Fold 3: 0.038958\n",
      "  Fold 4: 0.005148\n",
      "  Fold 5: 0.008821\n",
      "Baseline (last return) Allocation Sharpe-like avg: -0.000803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Paths\n",
    "# ------------------------------------------------\n",
    "DATA_PATH = Path.home() / \"Documents/kaggle/hull_tactical/data\"\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Load data with Polars\n",
    "# ------------------------------------------------\n",
    "train = pl.read_csv(DATA_PATH / \"train.csv\")\n",
    "test  = pl.read_csv(DATA_PATH / \"test.csv\")  # only used for column intersection\n",
    "\n",
    "# Cast non-date columns to float\n",
    "train = train.with_columns(\n",
    "    pl.all().exclude(\"date_id\").cast(pl.Float64, strict=False)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Simple mean imputation\n",
    "# ------------------------------------------------\n",
    "train_filled = train.with_columns([\n",
    "    pl.when(pl.col(c).is_null())\n",
    "      .then(pl.col(c).mean())\n",
    "      .otherwise(pl.col(c))\n",
    "      .alias(c)\n",
    "    for c in train.columns if c != \"date_id\"\n",
    "])\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Define common features\n",
    "# ------------------------------------------------\n",
    "train_cols = set(train_filled.columns)\n",
    "test_cols  = set(test.columns)\n",
    "\n",
    "common_cols = train_cols & test_cols\n",
    "BASE_FEATURE_COLS = sorted(common_cols - {\"is_scored\"})\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Sort by time\n",
    "# ------------------------------------------------\n",
    "train_sorted = train_filled.sort(\"date_id\")\n",
    "\n",
    "# Target\n",
    "y = train_sorted[\"market_forward_excess_returns\"].to_numpy()\n",
    "\n",
    "# Features\n",
    "X = train_sorted.select(BASE_FEATURE_COLS).to_pandas()\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "N = len(y)\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "print(\"Baseline feature columns:\", len(BASE_FEATURE_COLS))\n",
    "\n",
    "# Global return std for Kelly-ish stuff\n",
    "GLOBAL_RET_STD = float(np.std(y))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Walk-forward splits\n",
    "# ------------------------------------------------\n",
    "fractions = [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "bounds = [int(f * N) for f in fractions]\n",
    "\n",
    "fold_indices = []\n",
    "for i in range(5):\n",
    "    train_end = bounds[i]\n",
    "    val_start = bounds[i]\n",
    "    val_end   = bounds[i+1]\n",
    "    fold_indices.append((np.arange(0,train_end), np.arange(val_start,val_end)))\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#   BASE ALLOCATION STRATEGIES  \n",
    "#   (the ones you've already tested)\n",
    "# ======================================================================\n",
    "\n",
    "# 1) ✔ Tanh scaling (default, stable)\n",
    "def alloc_tanh(pred):\n",
    "    EDGE_SCALE = 50.0\n",
    "    a = 1.0 + np.tanh(pred * EDGE_SCALE)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 2) ✔ Linear scaling (simple, can be volatile)\n",
    "def alloc_linear(pred):\n",
    "    SCALE = 300.0\n",
    "    a = 1.0 + pred * SCALE\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 3) ✔ Piecewise (momentum-style)\n",
    "def alloc_piecewise(pred):\n",
    "    a = np.where(pred > 0, 1.25, 0.75)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 4) ✔ Asymmetric tanh (more long than short)\n",
    "def alloc_asymmetric(pred):\n",
    "    SCALE_UP = 60.0\n",
    "    SCALE_DOWN = 30.0\n",
    "    pos = 1.0 + np.tanh(pred * SCALE_UP)\n",
    "    neg = 1.0 + np.tanh(pred * SCALE_DOWN)\n",
    "    a = np.where(pred >= 0, pos, neg)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 5) ✔ Softplus (smooth convex response)\n",
    "def alloc_softplus(pred):\n",
    "    SCALE = 70.0\n",
    "    x = pred * SCALE\n",
    "    a = 1.0 + (np.log1p(np.exp(x)) - 0.5) / 20.0\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 6) ✔ Clipped sign (very simple and robust)\n",
    "def alloc_sign(pred):\n",
    "    a = 1.0 + 0.5 * np.sign(pred)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#   ADVANCED ALLOCATION STRATEGIES\n",
    "#   (volatility scaling, thresholds, Kelly-ish, regime, rolling Sharpe)\n",
    "# ======================================================================\n",
    "\n",
    "# 7) Volatility-scaled softplus\n",
    "def alloc_softplus_vol(pred):\n",
    "    WINDOW = 20\n",
    "    SCALE = 70.0\n",
    "\n",
    "    # True short-circuit safe softplus\n",
    "    def softplus_safe(z):\n",
    "        z = np.asarray(z)\n",
    "        out = np.empty_like(z)\n",
    "\n",
    "        mask = z > 30\n",
    "        out[mask] = z[mask]\n",
    "        out[~mask] = np.log1p(np.exp(z[~mask]))\n",
    "\n",
    "        return out\n",
    "\n",
    "    s = pd.Series(pred)\n",
    "    vol = s.rolling(WINDOW, min_periods=1).std().to_numpy()\n",
    "\n",
    "    # Safe volatility\n",
    "    safe_vol = np.where((vol <= 1e-12) | (~np.isfinite(vol)), 1e-6, vol)\n",
    "\n",
    "    # Normalize\n",
    "    norm = pred / safe_vol\n",
    "    norm = np.where(~np.isfinite(norm), 0.0, norm)\n",
    "\n",
    "    # Softplus input\n",
    "    x = norm * SCALE\n",
    "    x = np.where(~np.isfinite(x), 0.0, x)\n",
    "\n",
    "    # Apply fully safe softplus\n",
    "    sp = softplus_safe(x)\n",
    "\n",
    "    # Final allocation\n",
    "    a = 1.0 + (sp - 0.5) / 20.0\n",
    "    a = np.where(~np.isfinite(a), 1.0, a)\n",
    "\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 8) Thresholded tanh (ignore small/noisy signals)\n",
    "def alloc_tanh_threshold(pred):\n",
    "    THRESH = 0.0002  # tune this\n",
    "    pred_thr = np.where(np.abs(pred) < THRESH, 0.0, pred)\n",
    "    EDGE_SCALE = 50.0\n",
    "    a = 1.0 + np.tanh(pred_thr * EDGE_SCALE)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 9) Kelly-inspired allocation\n",
    "#    f* ~ edge / variance. Here we approx edge ~ pred, variance ~ GLOBAL_RET_STD^2.\n",
    "def alloc_kelly(pred):\n",
    "    sigma2 = GLOBAL_RET_STD**2 + 1e-12\n",
    "    EDGE_SCALE = 1.0  # treat pred itself as expected return\n",
    "    f_raw = (pred * EDGE_SCALE) / sigma2\n",
    "    f_clipped = np.clip(f_raw, -1.0, 1.0)  # don't exceed 1x bet either way\n",
    "    a = 1.0 + f_clipped\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 10) Regime-switching: low-vol uses aggressive softplus, high-vol shrinks bets\n",
    "def alloc_regime_softplus(pred):\n",
    "    WINDOW = 20\n",
    "    s = pd.Series(pred)\n",
    "    vol = s.rolling(WINDOW, min_periods=1).std().to_numpy()\n",
    "    median_vol = np.nanmedian(vol) if np.any(np.isfinite(vol)) else 0.0\n",
    "\n",
    "    high_vol = vol > median_vol\n",
    "\n",
    "    # Low-vol: regular softplus\n",
    "    a_low = alloc_softplus(pred)\n",
    "\n",
    "    # High-vol: compressed tanh around 1.0 (less leverage)\n",
    "    SCALE_HV = 20.0\n",
    "    a_high = 1.0 + 0.5 * np.tanh(pred * SCALE_HV)  # half range\n",
    "\n",
    "    a = np.where(high_vol, a_high, a_low)\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# 11) Softplus scaled by rolling Sharpe of the signal\n",
    "def alloc_softplus_sharpe(pred):\n",
    "    WINDOW = 60\n",
    "    ALPHA = 0.5\n",
    "\n",
    "    def softplus_safe(z):\n",
    "        return np.where(z > 30, z, np.log1p(np.exp(z)))\n",
    "\n",
    "    s = pd.Series(pred)\n",
    "\n",
    "    roll_mean = s.rolling(WINDOW, min_periods=5).mean().to_numpy()\n",
    "    roll_std  = s.rolling(WINDOW, min_periods=5).std().to_numpy()\n",
    "\n",
    "    # Safe std\n",
    "    safe_std = np.where((roll_std <= 1e-12) | (~np.isfinite(roll_std)), 1e-6, roll_std)\n",
    "\n",
    "    # Rolling Sharpe\n",
    "    roll_sharpe = roll_mean / safe_std\n",
    "    roll_sharpe = np.where(~np.isfinite(roll_sharpe), 0.0, roll_sharpe)\n",
    "\n",
    "    # Factor in [0,1]\n",
    "    factor = 0.5 + 0.5 * np.tanh(ALPHA * roll_sharpe)\n",
    "    factor = np.where(~np.isfinite(factor), 0.5, factor)\n",
    "\n",
    "    # Base allocation (softplus)\n",
    "    x = pred * 70.0\n",
    "    x = np.where(~np.isfinite(x), 0.0, x)\n",
    "    sp = softplus_safe(x)\n",
    "    base = 1.0 + (sp - 0.5) / 20.0\n",
    "\n",
    "    # Scale by rolling Sharpe\n",
    "    a = 1.0 + (base - 1.0) * factor\n",
    "    a = np.where(~np.isfinite(a), 1.0, a)\n",
    "\n",
    "    return np.clip(a, 0.0, 2.0)\n",
    "\n",
    "# ======================================================================\n",
    "#   Sharpe-like competition evaluation\n",
    "# ======================================================================\n",
    "def sharpe_like_strategy(y_true, allocation):\n",
    "    strat = allocation * y_true\n",
    "    return float(np.mean(strat) / (np.std(strat) + 1e-9))\n",
    "\n",
    "\n",
    "def pretty_print_scores(name, scores):\n",
    "    print(f\"{name} per fold:\")\n",
    "    for i, s in enumerate(scores, 1):\n",
    "        print(f\"  Fold {i}: {s:.6f}\")\n",
    "    print(f\"{name} avg: {np.mean(scores):.6f}\\n\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#   SELECT STRATEGY HERE (ONE ONLY)\n",
    "#   (keeping your known last-return scores in comments)\n",
    "# ======================================================================\n",
    "# allocation_fn = alloc_softplus      # last return 0.009228\n",
    "# allocation_fn = alloc_piecewise     # last return 0.002353\n",
    "# allocation_fn = alloc_tanh          # last return -0.008881\n",
    "# allocation_fn = alloc_linear        # last return -0.017213\n",
    "# allocation_fn = alloc_asymmetric    # last return -0.005558\n",
    "# allocation_fn = alloc_sign          # last return -0.005170\n",
    "\n",
    "# Advanced ones (not yet measured; you'll fill in comments as you test)\n",
    "allocation_fn = alloc_softplus_vol # last return\n",
    "# allocation_fn = alloc_tanh_threshold # last return -0.008884\n",
    "# allocation_fn = alloc_kelly # last return -0.016253\n",
    "# allocation_fn = alloc_regime_softplus # last return 0.005810\n",
    "# allocation_fn = alloc_softplus_sharpe # last return 0.009759\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Baseline: last-return signal → allocation → strategy Sharpe\n",
    "# ------------------------------------------------\n",
    "scores_last = []\n",
    "\n",
    "for train_idx, val_idx in fold_indices:\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    # Last return baseline signal\n",
    "    s_last = y[val_idx - 1]\n",
    "    a_last = allocation_fn(s_last)\n",
    "    scores_last.append(sharpe_like_strategy(y_val, a_last))\n",
    "\n",
    "pretty_print_scores(\"Baseline (last return) Allocation Sharpe-like\", scores_last)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
